---
title: 机器学习入门了解一下（支持向量机）-下
date: 2017-12-30 13:05:11
categories: [技术向]
tags: [Python,机器学习,SVM]
---


---------------

*也仅仅只是了解一下，一下下*

---------------


- **这里将使用到 Scikit-Learn 、 Matplotlib 、 Pandas 、 Numpy 等 Python 第三方库**

-----------------

# 准备工作

## 获取数据集

![UCI][1]

从 [UCI - Machine Learning Repository][2] 选择一个数据集，部分描述如下：

```
...
7. Attribute information:
   For more information, read [Cortez et al., 2009].

   Input variables (based on physicochemical tests):
   1 - fixed acidity
   2 - volatile acidity
   3 - citric acid
   4 - residual sugar
   5 - chlorides
   6 - free sulfur dioxide
   7 - total sulfur dioxide
   8 - density
   9 - pH
   10 - sulphates
   11 - alcohol
   Output variable (based on sensory data): 
   12 - quality (score between 0 and 10)
...
```


## Python 环境 + 各种库

准备好之后就可以继续了...


-----------------------

# 大概流程

看了一下数据集的描述，假装分析了一波（实则 Google + Baidu 了一会儿），然后对数据集进行下面三个简单步骤：

![pipeline][3]



-----------------------


#  开始搬砖



## 引入各种需要的库

如：
```
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn import svm
from sklearn.metrics import *
from sklearn.model_selection import *
from sklearn.feature_selection import *
from sklearn.pipeline import Pipeline
from sklearn import linear_model
from sklearn import ensemble
# from sklearn import neighbors
# from sklearn import tree
# from sklearn.decomposition import PCA
# from scipy.stats import pearsonr
```

然后

-------------------------

## 使用 Pandas 加载 .csv

```
def __loadData(self):
        self.data = pd.read_csv(
            './data/wine-quality/winequality-white.csv', sep=';')
```


-------------------------

## 数据预处理

具体内容需要 Google / Baidu 了解一下

- 为什么要数据预处理？
- 数据预处理方式有哪些？
- ...


![数据预处理][4]




```
...
# 后面将会用到 Pipeline ，使用更加简洁
def __process(self, data):
    scaler = preprocessing.StandardScaler().fit(data)
    scaled = scaler.transform(data)
    return scaled
...
```


-------------------------



## 特征选择

- 具体内容需要 Google / Baidu 了解一下 again

- 下图参考一下

![特征工程][5]

```
# 训练基模型，选择权值系数较高的特征
model = SelectFromModel( linear_model.LogisticRegression(penalty="l1", C=0.1) )
# L1惩罚项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要
```

- 那么问题来了

- 为什么要进行特征选择？

> 特征选择主要有两个目的：
> 1. 减少特征数量、降维，使模型泛化能力更强，减少过拟合
> 2. 增强对特征和特征值之间的理解

- 根据特征选择的形式又可以将特征选择方法分为3种

1. Filter
> 过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。

2. Wrapper
> 包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。

3. Embedded
> 嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。



------------------------


## 训练模型

### GridSearch 网格搜索

- [GridSearch][6] 了解一下
```
# 网格搜索（因为很费时间所以就跑一次后直接记录下参数）
# p_range = [0.01, 0.1, 0.5, 0.7, 1, 10, 100]
# hp = {'kernel': ['linear', 'rbf'],
#       'C': p_range,
#       'gamma': p_range}
# #'epsilon': [0.1, 0.2, 0.3, 0.4, 0.5],
# #'degree': [3, 4, 5]}
# gcv = GridSearchCV(svm.SVR(), hp, cv=10)
```

### Pipeline / 管道

- [Pipeline][7] 了解一下

> Pipeline 其实就像水管一样，将数据依次走过进行对应的处理

![Pipeline][8]

```
# 这里的参数是从上面的 GridSearch 拿到的最优参数
svr = svm.SVR(kernel='rbf', C=1, gamma=0.5, degree=3, epsilon=0.1)

clf = Pipeline([  # 管道
            ('ssc', preprocessing.StandardScaler()),
            ('mod', model), # 这里的 model 用到的是上面特征选择拿到的 model
            
            # 尝试一下各种方法↓
            # ('pca', PCA(n_components=5)),
            # ('rfe', RFE(linear_model.LinearRegression(),
            #             n_features_to_select=5)),
            # ('skb', SelectKBest(chi2, k=6)),
            
            # 模型训练
            # ('lr', ensemble.RandomForestClassifier(n_estimators=1000))
            ('svr', svr)
        ])

```

### 拿到模型

走完 Pipeline 就训练出模型了，然后

```
...
# fit 一下，print 一下看看结果如何
clf.fit(self.xTrain, self.yTrain)
        # print(gcv.estimator, '\n\n\n')
        self.predict = clf.predict(self.xTest)
        print('score:\n', clf.score(self.xTest, self.yTest), '\n')
        print('MSE:\n', mean_squared_error(self.yTest, self.predict))
# MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。
...
```

- score 为**准确率**， MSE 为**预测值和真实值的差距的平方和**。
- 也就是说 score 越大越好， MSE 越小越好

![res-score-0][9]

- 然而有点难受， score 才 0.48， MSE 有 0.40
- 不过谁能想到，刚开始直接使用 SVR 只有 0.2 不到的 score
- 能提升到 0.48 已经很 nice 了，饶了我这个刚入门的菜鸡吧 ＼( ´・∧・｀)／ 


------------------


## 绘图

作出结果比对图能更直观地看到成果，下面就用 Matplotlib 来画画吧

```
...
# 代码略，最后面有全部代码...
...
```

得到这样的两张图：

![res-0-1][10]

**<p style='text-align: center'>橙色为预测结果</p>**

![res-0-2][11]


-----------------


## 换 **SVR** 为 **RandomForestClassifier**

- [RandomForestClassifier 了解一下][12]

- 因为使用 **SVR** 得到的结果比较不满意

- 所以尝试了几种方法，发现使用**随机森林分类**更加适用于该数据集

```
clf = Pipeline([  # 管道
            ('ssc', preprocessing.StandardScaler()),
            ('mod', model),
            
            # 即在这里改用 RandomForestClassifier
            ('lr', ensemble.RandomForestClassifier(n_estimators=1000))
            # ('svr', svr)
        ])
```

- 其中 n_estimators 为子树数量，为随机森林重要参数之一，一般情况下数量越多模型性能越好

- 看图：

![res-score][13]

**可以看到提升的很明显**

![res-1-1][14]

![res-1-2][15]



- 所以说选对算法也是很重要的

- 总的来说..水太深了..

- 那么我们就点到为止（溜了溜了


-----------------------

## 全部代码

```

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn import svm
from sklearn.metrics import *
from sklearn.model_selection import *
from sklearn.feature_selection import *
from sklearn.pipeline import Pipeline
from sklearn import linear_model
from sklearn import ensemble
# from sklearn import neighbors
# from sklearn import tree
# from sklearn.decomposition import PCA
# from scipy.stats import pearsonr


class Shit:

    def __init__(self):
        self.__loadData()

    def __loadData(self):
        self.data = pd.read_csv(
            './data/wine-quality/winequality-white.csv', sep=';')

    def __process(self, data):
        scaler = preprocessing.StandardScaler().fit(data)
        scaled = scaler.transform(data)
        return scaled

    def getXy(self):
        y = self.data.quality
        x = self.data.drop('quality', axis=1)
        # x = self.__process(x)

        self.xTrain, self.xTest, self.yTrain, self.yTest = train_test_split(
            x, y, test_size=0.2, random_state=1, stratify=y)

    def action(self):
        # 网格搜索（因为很费时间所以就跑一次后直接记录下参数）
        # p_range = [0.01, 0.1, 0.5, 0.7, 1, 10, 100]
        # hp = {'kernel': ['linear', 'rbf'],
        #       'C': p_range,
        #       'gamma': p_range}
        # #'epsilon': [0.1, 0.2, 0.3, 0.4, 0.5],
        # #'degree': [3, 4, 5]}
        # gcv = GridSearchCV(svm.SVR(), hp, cv=10)

        svr = svm.SVR(kernel='rbf', C=1, gamma=0.5, degree=3, epsilon=0.1)

        model = SelectFromModel(  # 训练基模型，选择权值系数较高的特征
            linear_model.LogisticRegression(penalty="l1", C=0.1))
        # L1惩罚项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要

        clf = Pipeline([  # 管道
            ('ssc', preprocessing.StandardScaler()),
            ('mod', model),
            
            # 尝试一下各种方法↓
            # ('pca', PCA(n_components=5)),
            # ('rfe', RFE(linear_model.LinearRegression(),
            #             n_features_to_select=5)),
            # ('skb', SelectKBest(chi2, k=6)),

            # 模型训练
            # ('lr', ensemble.RandomForestClassifier(n_estimators=1000))
            ('svr', svr)
        ])

        clf.fit(self.xTrain, self.yTrain)
        # print(gcv.estimator, '\n\n\n')
        self.predict = clf.predict(self.xTest)
        print('score:\n', clf.score(self.xTest, self.yTest), '\n')
        print('MSE:\n',
              mean_squared_error(self.yTest, self.predict))
        # MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。

    def draw(self):

        # 画第一张图
        s_size = 100
        plt.figure(figsize=(7, 4))
        plt.plot(np.arange(s_size), self.yTest[0:s_size], 'o-', label='true')
        plt.plot(np.arange(s_size), self.predict[
                 0:s_size], 'o-', label='predict')
        plt.xlabel('index')
        plt.ylabel('quality')
        plt.title('Result of predict')

        # 画第二张图
        count_yTest = {}
        count_predict = {}
        for i in self.yTest:
            count_yTest[i] = count_yTest[i] + \
                1 if i in count_yTest.keys() else 0
        for j in np.around(self.predict):
            count_predict[j] = count_predict[j] + \
                1 if j in count_predict.keys() else 0
        count_yTest = dict(sorted(count_yTest.items()))
        count_predict = dict(sorted(count_predict.items()))

        pX1 = [n - 0.2 for n in count_yTest.keys()]
        pX2 = [n + 0.2 for n in count_predict.keys()]
        pY1 = list(map(lambda x: x, count_yTest.values()))
        pY2 = list(map(lambda x: x, count_predict.values()))
        plt.figure(figsize=(7, 4))
        plt.bar(pX1, pY1, alpha=0.8, width=0.4)
        plt.bar(pX2, pY2, alpha=0.8, width=0.4)
        plt.xlim(0, 10)
        plt.xticks(np.arange(11))
        for x, y in zip(pX1, pY1):
            plt.text(x, y, y, ha='center', va='bottom')
        for x, y in zip(pX2, pY2):
            plt.text(x, y, y, ha='center', va='bottom')
        plt.xlabel('Quality ( True / Predict )')
        plt.ylabel('Total')
        plt.show()

test = Shit()
test.getXy()
test.action()
test.draw()

```


  [1]: http://otwin1ura.bkt.clouddn.com/blog/%E5%9B%BE%E7%89%875-1.png
  [2]: http://archive.ics.uci.edu/ml/
  [3]: http://otwin1ura.bkt.clouddn.com/blog/%E5%9B%BE%E7%89%876-1.png
  [4]: http://otwin1ura.bkt.clouddn.com/blog/%E5%9B%BE%E7%89%877-1.png
  [5]: http://otwin1ura.bkt.clouddn.com/blog/8-1.jpg
  [6]: http://scikit-learn.org/0.15/modules/generated/sklearn.grid_search.GridSearchCV.html
  [7]: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html
  [8]: http://otwin1ura.bkt.clouddn.com/blog/%E5%9B%BE9-1.png
  [9]: http://otwin1ura.bkt.clouddn.com/blog/res-0-3.png
  [10]: http://otwin1ura.bkt.clouddn.com/blog/res-0-1.png
  [11]: http://otwin1ura.bkt.clouddn.com/blog/res-0-2.png
  [12]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
  [13]: http://otwin1ura.bkt.clouddn.com/blog/res-1-3.png
  [14]: http://otwin1ura.bkt.clouddn.com/blog/res-1-1.png
  [15]: http://otwin1ura.bkt.clouddn.com/blog/res-1-2.png